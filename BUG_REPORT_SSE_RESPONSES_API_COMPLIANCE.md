# Bug Report: OpenAI Responses API v1 Compliance & SSE Stream Handling

**Report erstellt:** 5. November 2025  
**Reviewer:** Senior Backend Developer (Spring Boot, Spring Reactor, R2DBC, SSE)  
**Severity:** HIGH (Kritische Inkonsistenzen gefunden)  
**Scope:** MCP Tool Events + Core Response Lifecycle (keine built-in Tools wie web_search/file_search)

---

## Executive Summary

Die Backend-Implementierung (`ResponseStreamService`, `ResponseStreamController`) zeigt **kritische Abweichungen** von der OpenAI Responses API v1 Spezifikation. Als SSE-Proxy zwischen OpenAI und Frontend werden wichtige Lifecycle-Events nicht korrekt weitergeleitet, was zu inkonsistentem Client-Verhalten, fehlender Fehlerbehandlung und potenziellen Stream-Leaks f√ºhrt.

**Hauptprobleme:**
1. ‚ùå **Fehlende Lifecycle-Events** (`response.created`, `response.completed`, `response.incomplete`)
2. ‚ùå **Unvollst√§ndige Error-Event-Behandlung** 
3. ‚ö†Ô∏è **R2DBC Backpressure-Risiken** bei hoher Last
4. ‚ö†Ô∏è **Fehlende Stream-Cleanup-Garantien**
5. ‚ö†Ô∏è **Unvollst√§ndige MCP Tool-Event-Abdeckung**

---

## üî¥ KRITISCH: Fehlende Lifecycle-Events

### Problem

Die API-Spec definiert obligatorische Stream-Lifecycle-Events:

```
response.created       ‚Üí Stream startet (IMMER erstes Event)
response.in_progress   ‚Üí Stream l√§uft (bei jedem Chunk)
response.completed     ‚Üí Stream erfolgreich beendet
response.incomplete    ‚Üí Stream vorzeitig abgebrochen (length limit)
```

**Backend-Implementierung (`ResponseStreamService.handleEvent`)**:
```java
return switch (eventName) {
    case "response.output_text.delta" -> handleTextDelta(payload, state);
    case "response.output_text.done" -> handleTextDone(payload, state, data);
    case "response.output_item.added" -> handleOutputItemAdded(payload, state);
    // ... nur Tool-Events
    default -> Mono.empty();  // ‚ùå ALLE Lifecycle-Events werden ignoriert!
};
```

**Was fehlt:**
```java
case "response.created" -> handleResponseCreated(payload, state);
case "response.in_progress" -> handleResponseInProgress(payload, state);
case "response.completed" -> handleResponseCompleted(payload, state);
case "response.incomplete" -> handleResponseIncomplete(payload, state);
```

### Auswirkungen

1. **Frontend hat keine Stream-State-Awareness**
   - Keine Information wann Stream wirklich startet (`response.created`)
   - Keine Unterscheidung zwischen "l√§uft" und "beendet"
   - Client wei√ü nicht, ob Response vollst√§ndig oder abgebrochen wurde

2. **Conversation-Persistierung unzuverl√§ssig**
   - Ohne `response.completed` kein definierter Zeitpunkt f√ºr finale DB-Speicherung
   - Response-ID aus `response.created` wird nicht erfasst (ben√∂tigt f√ºr `previous_response_id` in Folge-Requests)

3. **Fehlerhafte UX f√ºr Token-Limits**
   - `response.incomplete` (finish_reason: "length") wird nicht behandelt
   - User bekommt keine Info √ºber abgeschnittene Antworten

### L√∂sungsstrategie

```java
// In ResponseStreamService.handleEvent() erg√§nzen:

case "response.created" -> handleResponseCreated(payload, state);
case "response.in_progress" -> Mono.empty(); // Optional: f√ºr Monitoring
case "response.completed" -> handleResponseCompleted(payload, state);
case "response.incomplete" -> handleResponseIncomplete(payload, state);

// Neue Handler:
private Mono<Void> handleResponseCreated(JsonNode payload, StreamState state) {
    String responseId = payload.path("response").path("id").asText();
    state.responseId = responseId; // StreamState erweitern!
    
    return conversationService.updateConversationResponseId(
        state.conversationId, 
        responseId
    ).then();
}

private Mono<Void> handleResponseCompleted(JsonNode payload, StreamState state) {
    return conversationService.finalizeConversation(
        state.conversationId,
        state.responseId
    ).then();
}

private Mono<Void> handleResponseIncomplete(JsonNode payload, StreamState state) {
    JsonNode response = payload.path("response");
    String reason = response.path("status_details").path("reason").asText("unknown");
    
    return conversationService.markConversationIncomplete(
        state.conversationId,
        reason
    ).then();
}
```

---

## üî¥ KRITISCH: Unvollst√§ndige Error-Event-Behandlung

### Problem

API-Spec definiert 3 Fehler-Event-Typen:

1. **`response.failed`** - Stream-Fehler nach Start (inkl. error-Details)
2. **`response.error`** - Fehler w√§hrend Generierung (z.B. rate limit)
3. **`error`** - Kritische Fehler (z.B. ung√ºltiger API-Key)

**Backend-Implementierung:**
```java
// ResponseStreamService.buildErrorEvent() - nur bei lokalen Exceptions
private ServerSentEvent<String> buildErrorEvent(Throwable error) {
    // ...
    return ServerSentEvent.<String>builder(errorNode.toString())
            .event("response.failed")  // ‚ùå Nur EIGENE Fehler, nicht von OpenAI!
            .build();
}
```

**handleEvent() behandelt KEINE Error-Events:**
```java
return switch (eventName) {
    // ... nur Success-Events
    default -> Mono.empty();  // ‚ùå Fehler-Events werden nicht erkannt!
};
```

### Auswirkungen

1. **OpenAI-Fehler werden blind weitergeleitet**
   - Client erh√§lt raw `response.failed`/`error` Events ohne Backend-Kenntnis
   - Keine DB-Persistierung von Fehler-Status
   - Conversation bleibt in "in_progress"-State h√§ngen

2. **Keine Retry-Logik m√∂glich**
   - Rate-Limit-Fehler (`response.error` mit `rate_limit_exceeded`) werden nicht erkannt
   - Transiente Fehler nicht von permanenten unterscheidbar

3. **Memory-Leaks bei Fehlern**
   - `StreamState.clear()` wird nur bei erfolgreicher Completion aufgerufen (via `doFinally`)
   - Bei upstream-Errors k√∂nnte State nicht aufger√§umt werden

### L√∂sungsstrategie

```java
// In handleEvent() erg√§nzen:
case "response.failed" -> handleResponseFailed(payload, state);
case "response.error" -> handleResponseError(payload, state);
case "error" -> handleCriticalError(payload, state);

// Handler implementieren:
private Mono<Void> handleResponseFailed(JsonNode payload, StreamState state) {
    JsonNode response = payload.path("response");
    JsonNode error = response.path("error");
    
    String errorCode = error.path("code").asText("unknown");
    String errorMessage = error.path("message").asText("");
    
    return conversationService.markConversationFailed(
        state.conversationId,
        errorCode,
        errorMessage
    ).then();
}

private Mono<Void> handleResponseError(JsonNode payload, StreamState state) {
    JsonNode error = payload.path("error");
    String code = error.path("code").asText();
    
    // Rate-Limit spezielle Behandlung
    if ("rate_limit_exceeded".equals(code)) {
        log.warn("Rate limit hit for conversation {}", state.conversationId);
        // Optional: Signal f√ºr Retry-Queue
    }
    
    return conversationService.logError(
        state.conversationId,
        code,
        error.path("message").asText()
    ).then();
}

private Mono<Void> handleCriticalError(JsonNode payload, StreamState state) {
    // Auth-Fehler etc. - Stream wird abgebrochen
    return conversationService.markConversationFailed(
        state.conversationId,
        "critical_error",
        payload.path("error").path("message").asText()
    ).then();
}
```

**Wichtig:** Error-Handler m√ºssen **VOR** `cloneEvent()` ausgef√ºhrt werden, damit Client nicht Fehler-Event empf√§ngt bevor Backend reagiert hat!

```java
// Aktuell:
Flux<ServerSentEvent<String>> processed = upstream.concatMap(event -> 
    handleEvent(event, state).thenReturn(cloneEvent(event))  // ‚ùå Event wird IMMER weitergeleitet
);

// Besser:
Flux<ServerSentEvent<String>> processed = upstream.concatMap(event -> 
    handleEvent(event, state)
        .then(shouldForwardEvent(event)  // üîß Optionale Filterung
            ? Mono.just(cloneEvent(event))
            : Mono.empty()
        )
);
```

---

## ‚ö†Ô∏è WARNUNG: Fehlende Content-Part Events

### Problem

API-Spec definiert feingranulare Content-Events:

```
response.content_part.added    ‚Üí Neuer Content-Teil beginnt
response.content_part.done     ‚Üí Content-Teil beendet
response.output_item.done      ‚Üí Gesamtes Output-Item fertig
```

**Backend behandelt nur:**
- ‚úÖ `response.output_item.added`
- ‚ùå `response.content_part.added` - fehlt
- ‚ùå `response.content_part.done` - fehlt
- ‚ùå `response.output_item.done` - fehlt

### Auswirkungen

**Bei Multi-Content-Responses** (z.B. Text + Reasoning Summary):
```
OpenAI sendet:
1. response.output_item.added (item_id: "msg_1", type: "output_text")
2. response.content_part.added (content_index: 0)
3. response.output_text.delta (mehrfach)
4. response.content_part.done (content_index: 0)  ‚ùå NICHT BEHANDELT
5. response.output_item.done (item_id: "msg_1")   ‚ùå NICHT BEHANDELT
```

**Problem:** Backend persistiert Text bereits bei `output_text.done`, **ABER:**
- Kein Signal dass das gesamte Item komplett ist
- Bei Multi-Part Items (z.B. Reasoning + Text) wird m√∂glicherweise zu fr√ºh gespeichert

### L√∂sungsstrategie

```java
case "response.content_part.added" -> handleContentPartAdded(payload, state);
case "response.content_part.done" -> handleContentPartDone(payload, state);
case "response.output_item.done" -> handleOutputItemDone(payload, state);

private Mono<Void> handleOutputItemDone(JsonNode payload, StreamState state) {
    JsonNode item = payload.path("item");
    String itemId = item.path("id").asText();
    
    // Finale Validierung & Persistierung
    return conversationService.finalizeOutputItem(
        state.conversationId,
        itemId
    ).then();
}
```

---

## ‚ö†Ô∏è WARNUNG: Unvollst√§ndige MCP Tool-Event-Abdeckung

### Problem

API-Spec definiert f√ºr MCP-Tools folgende Events:

```
response.mcp_call.in_progress          ‚Üí MCP Tool startet
response.mcp_call_arguments.delta      ‚Üí Argumente werden gestreamt  
response.mcp_call_arguments.done       ‚Üí Argumente vollst√§ndig
response.mcp_call.completed            ‚Üí MCP Tool fertig
response.mcp_call.failed               ‚Üí MCP Tool fehlgeschlagen
response.mcp_list_tools.in_progress    ‚Üí Tool-Liste wird abgerufen
response.mcp_list_tools.completed      ‚Üí Tool-Liste verf√ºgbar
response.mcp_list_tools.failed         ‚Üí Tool-Liste Fehler
```

**Backend behandelt:**
- ‚úÖ `response.mcp_call_arguments.delta`
- ‚úÖ `response.mcp_call_arguments.done`
- ‚úÖ `response.mcp_call.in_progress`
- ‚úÖ `response.mcp_call.completed`
- ‚úÖ `response.mcp_call.failed`
- ‚úÖ `response.mcp_list_tools.in_progress`
- ‚úÖ `response.mcp_list_tools.completed`
- ‚úÖ `response.mcp_list_tools.failed`

**ABER:** Es gibt Probleme bei der ID-Behandlung und fehlende `executing` Events.

### Auswirkungen

#### 1. call_id vs. item_id Verwirrung

**DB-Schema:**
```sql
CREATE TABLE tool_calls (
    id BIGINT PRIMARY KEY,          -- Interne DB-ID (auto-increment)
    item_id VARCHAR(255),            -- OpenAI Item-ID (z.B. "msg_1")
    call_id VARCHAR(255),            -- Tool Call-ID (z.B. "call_abc123")
    name VARCHAR(255),               -- Tool-Name (z.B. "get_weather")
    ...
);
```

**OpenAI sendet bei MCP-Calls:**
```json
{
  "type": "response.output_item.added",
  "item": {
    "id": "msg_1",              // ‚Üí item_id (unique per output item)
    "type": "mcp_call",
    "call_id": "call_abc123",   // ‚Üí call_id (tool-spezifisch, kann fehlen!)
    "name": "get_weather"
  }
}
```

**Backend-Logik (ResponseStreamService.java:266-271):**
```java
if ("mcp_call".equals(type)) {
    String callId = item.path("call_id").asText(null);
    if (callId == null || callId.isEmpty()) {
        callId = itemId;  // ‚ö†Ô∏è Fallback auf item_id
    }
    attributes.put("callId", callId);
}
```

**Problem:** 
- `call_id` kann laut API optional sein (V2__make_call_id_nullable.sql best√§tigt das)
- Der Fallback ist OK, **ABER** nicht dokumentiert warum
- Es ist unklar ob `call_id` und `item_id` immer gleich sind wenn `call_id` fehlt

**Kl√§rung:** Sind `item_id` und `call_id` bei MCP-Calls immer identisch wenn keine explizite `call_id` gesendet wird?

#### 2. Fehlende `executing` Event-Behandlung

Die API-Spec erw√§hnt:
```
response.mcp_call.in_progress   ‚úÖ Behandelt
response.mcp_call.executing     ‚ùå Fehlt (optional, zeigt aktive Ausf√ºhrung)
response.mcp_call.completed     ‚úÖ Behandelt
```

**Impact:** Niedrig - `executing` ist optional, aber f√ºr UX hilfreich (zeigt dass Tool aktiv arbeitet vs. nur gestartet).

#### 3. MCP List Tools Events sind "No-Op"

```java
private Mono<Void> handleMcpListToolsEvent(JsonNode payload, String status) {
    log.debug("MCP list tools event: {} for item {}", status, itemId);
    // ‚ùå These events are informational - no persistence needed yet
    return Mono.empty();
}
```

**M√∂gliche Verbesserung:** Diese Events k√∂nnten f√ºr Debugging/Audit-Log genutzt werden.

### L√∂sungsstrategie

#### A) Optionales `executing` Event

```java
case "response.mcp_call.executing" -> updateToolCallStatus(
    payload, state, ToolCallStatus.EXECUTING, null
);

// ToolCallStatus Enum erweitern:
public enum ToolCallStatus {
    IN_PROGRESS,
    EXECUTING,    // üîß Neu: Tool l√§uft aktiv (optional)
    COMPLETED,
    FAILED
}
```

**Alternative:** Wenn Status-Granularit√§t nicht ben√∂tigt wird, `executing` weiter ignorieren (aktuelles Verhalten OK).

#### B) call_id Dokumentation

```java
// Dokumentation im Code erg√§nzen:
if ("mcp_call".equals(type)) {
    // call_id ist optional laut API-Spec.
    // Fallback auf item_id ist valide, da beide denselben Call identifizieren.
    String callId = item.path("call_id").asText(null);
    if (callId == null || callId.isEmpty()) {
        callId = itemId;  
    }
    attributes.put("callId", callId);
}
```

#### C) MCP List Tools Tracking (optional, nice-to-have)

```java
private Mono<Void> handleMcpListToolsEvent(JsonNode payload, String status) {
    if ("completed".equals(status)) {
        log.info("MCP tools listed for conversation {}", state.conversationId);
        // Optional: Audit-Log oder Metrics
    }
    return Mono.empty();
}
```

**Hinweis:** Built-in Tools (web_search, file_search) sind out-of-scope, da nur MCP-Tools relevant sind.

---

## üî¥ KRITISCH: R2DBC Backpressure & Concurrency Issues

### Problem

**Streaming + R2DBC = Backpressure-Risiko**

Aktueller Flow:
```java
Flux<ServerSentEvent<String>> processed = upstream.concatMap(event -> 
    handleEvent(event, state)  // ‚ùå Kann DB-Writes triggern!
        .thenReturn(cloneEvent(event))
);
```

**Was passiert:**
1. SSE-Event kommt von OpenAI (schnell, ~100ms/token)
2. `handleEvent()` macht R2DBC-Write (langsamer, ~10-50ms)
3. `concatMap` wartet auf DB-Write **BEVOR** n√§chstes Event verarbeitet wird

**Risiken:**

### 1. Upstream-Timeout bei langsamen DB-Writes

```
OpenAI sendet:  Event1 ‚Üí Event2 ‚Üí Event3 ‚Üí ...
                  ‚Üì       ‚Üì        ‚Üì
Backend DB:     [Write1-50ms] ‚Üí [Write2-50ms] ‚Üí ...
                      ‚Üì
Upstream-Buffer voll ‚Üí OpenAI schlie√üt Stream!
```

### 2. StreamState-Corruption bei parallelen Requests

`StreamState` ist **NICHT thread-safe genug:**

```java
private static final class StreamState {
    private final Long conversationId;
    private final Map<Integer, StringBuilder> textByOutputIndex = new ConcurrentHashMap<>();
    private final Map<String, ToolCallTracker> toolCalls = new ConcurrentHashMap<>();
    // ‚ùå Fehlt: responseId, completionStatus, errorState
}
```

**Problem:** 
- `ConcurrentHashMap` sch√ºtzt nur Map-Operationen
- `StringBuilder` in `textByOutputIndex` ist **NICHT thread-safe!**

```java
// Race Condition m√∂glich:
private Mono<Void> handleTextDelta(JsonNode payload, StreamState state) {
    state.textByOutputIndex
        .computeIfAbsent(outputIndex, ignored -> new StringBuilder())
        .append(delta);  // ‚ùå StringBuilder nicht synchronized!
}
```

### 3. Memory Leaks bei Stream-Abbruch

```java
Flux<ServerSentEvent<String>> processed = upstream.concatMap(...)
    .doFinally(signal -> state.clear());  // ‚ö†Ô∏è Nur bei NORMALEM Abschluss!
```

**Problem:** Bei Client-Disconnect oder Upstream-Fehler:
- `doFinally` wird aufgerufen
- **ABER:** Laufende DB-Operationen werden nicht gecancelt!
- R2DBC-Connections k√∂nnten leak'en

### L√∂sungsstrategie

#### A) Backpressure-Safe Processing

```java
// Option 1: Entkopplung via Buffer + flatMap
Flux<ServerSentEvent<String>> processed = upstream
    .flatMap(event -> 
        handleEvent(event, state)
            .subscribeOn(Schedulers.boundedElastic())  // Separate DB-Thread
            .thenReturn(cloneEvent(event)),
        256  // Concurrency limit
    )
    .doFinally(signal -> state.clear());

// Option 2: Fire-and-Forget f√ºr unkritische Writes
Flux<ServerSentEvent<String>> processed = upstream
    .doOnNext(event -> 
        handleEvent(event, state)
            .subscribeOn(Schedulers.boundedElastic())
            .subscribe()  // ‚ùå Gef√§hrlich: Fehler gehen verloren!
    )
    .map(this::cloneEvent);
```

**Empfehlung:** **Option 1 mit bounded concurrency**
- Verhindert Upstream-Blockierung
- Erh√§lt Fehler-Propagierung
- Limitiert parallele DB-Writes (wichtig bei H2!)

#### B) Thread-Safe StreamState

```java
private static final class StreamState {
    private final Long conversationId;
    private volatile String responseId;  // Volatile f√ºr Visibility
    private volatile StreamStatus status = StreamStatus.ACTIVE;
    
    // Thread-safe Text-Akkumulation
    private final Map<Integer, AtomicReference<String>> textByOutputIndex = 
        new ConcurrentHashMap<>();
    
    // Thread-safe Append
    void appendText(int outputIndex, String delta) {
        textByOutputIndex
            .computeIfAbsent(outputIndex, k -> new AtomicReference<>(""))
            .updateAndGet(current -> current + delta);
    }
    
    String getText(int outputIndex) {
        AtomicReference<String> ref = textByOutputIndex.get(outputIndex);
        return ref != null ? ref.get() : "";
    }
}
```

#### C) R2DBC Connection Pool Tuning

**Aktuell:** Keine Pool-Konfiguration in `application.properties`!

```properties
# ‚ùå Fehlt komplett:
spring.r2dbc.pool.enabled=true
spring.r2dbc.pool.initial-size=10
spring.r2dbc.pool.max-size=50
spring.r2dbc.pool.max-idle-time=30m
spring.r2dbc.pool.max-acquire-time=PT3S
```

**Problem bei H2 In-Memory:**
- H2 unterst√ºtzt nur ~1024 parallele Connections
- Bei Streaming-Last k√∂nnten Connections ersch√∂pft werden

**L√∂sung:**
```properties
# F√ºr H2 In-Memory (Development):
spring.r2dbc.pool.enabled=true
spring.r2dbc.pool.initial-size=5
spring.r2dbc.pool.max-size=20  # H2 Limit beachten!
spring.r2dbc.pool.validation-query=SELECT 1

# F√ºr Production (PostgreSQL):
spring.r2dbc.pool.max-size=50
spring.r2dbc.pool.max-acquire-time=PT3S
```

---

## ‚ö†Ô∏è WARNUNG: Fehlende Refusal & Reasoning Events

### Problem

API-Spec definiert spezielle Content-Typen:

**Refusal (Moderation):**
```
response.refusal.delta ‚Üí Ablehnung wird gestreamt
response.refusal.done  ‚Üí Ablehnung komplett
```

**Reasoning (O1-Modelle):**
```
response.reasoning_summary.delta ‚Üí Denkschritte werden gestreamt
response.reasoning_summary.done  ‚Üí Reasoning fertig
```

**Backend:** Beide werden **komplett ignoriert**.

### Auswirkungen

1. **Moderation-Responses gehen verloren**
   - User sieht leeren Response wenn Content moderiert wird
   - Keine DB-Persistierung von Refusal-Reasons

2. **O1-Reasoning unsichtbar**
   - Bei O1-Modellen mit Reasoning-Output fehlt dieser komplett
   - Wichtig f√ºr Transparenz (OpenAI's "Chain-of-Thought")

### L√∂sungsstrategie

```java
case "response.refusal.delta" -> handleRefusalDelta(payload, state);
case "response.refusal.done" -> handleRefusalDone(payload, state);
case "response.reasoning_summary.delta" -> handleReasoningDelta(payload, state);
case "response.reasoning_summary.done" -> handleReasoningDone(payload, state);

private Mono<Void> handleRefusalDone(JsonNode payload, StreamState state) {
    String itemId = payload.path("item_id").asText();
    String refusalText = payload.path("refusal").asText();
    
    return conversationService.appendMessage(
        state.conversationId,
        MessageRole.ASSISTANT,
        refusalText,
        payload.toString(),
        payload.path("output_index").asInt(0),
        itemId
    ).then();
}
```

---

## üîß Zus√§tzliche Verbesserungsvorschl√§ge

### 1. Enhanced Logging f√ºr Debugging

```java
private Mono<Void> handleEvent(ServerSentEvent<String> event, StreamState state) {
    String eventName = event.event();
    
    // Metric-Tracking f√ºr unbekannte Events
    if (!KNOWN_EVENTS.contains(eventName)) {
        log.warn("‚ö†Ô∏è Unknown event type received: {} (conv_id: {})", 
                 eventName, state.conversationId);
        // Optional: Metric export f√ºr Monitoring
    }
    
    return switch (eventName) {
        // ...
    };
}
```

### 2. Circuit Breaker f√ºr DB-Writes

```java
@Bean
public ReactiveResilience4JCircuitBreakerFactory circuitBreakerFactory() {
    return new ReactiveResilience4JCircuitBreakerFactory();
}

// In ResponseStreamService:
private Mono<Void> handleTextDone(JsonNode payload, StreamState state, String rawJson) {
    return circuitBreaker.run(
        conversationService.updateMessageContent(...).then(),
        throwable -> Mono.fromRunnable(() -> 
            log.error("DB write failed, message queued for retry: {}", itemId)
        )
    );
}
```

### 3. Conversation State Machine

```java
public enum ConversationState {
    CREATED,
    STREAMING,
    COMPLETED,
    INCOMPLETE,
    FAILED,
    CANCELLED
}

// In Conversation Entity:
@Column
private ConversationState state = ConversationState.CREATED;

// Lifecycle-Methoden mit State-Validierung:
public void markCompleted() {
    if (this.state != ConversationState.STREAMING) {
        throw new IllegalStateException("Cannot complete conversation in state: " + state);
    }
    this.state = ConversationState.COMPLETED;
}
```

### 4. Structured Event Audit Log

```java
@Entity
@Table(name = "event_audit")
public class EventAudit {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;
    
    private Long conversationId;
    private String eventType;
    private String payload;
    private Instant timestamp;
    
    // F√ºr Debugging unbekannter Events & Compliance
}
```

---

## üìä Priorisierung

| Prio | Issue | Aufwand | Impact | Risiko |
|------|-------|---------|--------|--------|
| üî¥ P0 | Lifecycle-Events (`response.created`, `completed`) | Medium | Critical | Data Loss |
| üî¥ P0 | Error-Event-Handling | Medium | Critical | Silent Failures |
| üü† P1 | Backpressure-Strategie | High | High | Timeouts |
| üü† P1 | StreamState Thread-Safety | Low | High | Corruption |
| üü° P2 | MCP `executing` Event (optional) | Low | Low | UX Enhancement |
| üü° P2 | Content-Part Events | Low | Low | Edge Cases |
| üü¢ P3 | Refusal/Reasoning Events | Low | Low | Nice-to-Have |

**Hinweis:** Built-in Tool-Events (web_search, file_search) sind out-of-scope, da nur MCP-Tools relevant sind.

---

## üéØ Empfohlener Action Plan

### Phase 1: Critical Fixes (Woche 1)
1. ‚úÖ Lifecycle-Events implementieren (`response.created`, `completed`, `incomplete`)
2. ‚úÖ Error-Event-Handler (`response.failed`, `response.error`, `error`)
3. ‚úÖ StreamState um `responseId` und Status erweitern
4. ‚úÖ Conversation State Machine einf√ºhren

### Phase 2: Stability (Woche 2)
5. ‚úÖ Thread-safe StreamState (AtomicReference statt StringBuilder)
6. ‚úÖ Backpressure-Strategie mit `flatMap` + bounded concurrency
7. ‚úÖ R2DBC Pool-Konfiguration
8. ‚úÖ Enhanced Error-Logging f√ºr unbekannte Events

### Phase 3: Polish & Optional Features (Woche 3)
9. ‚öôÔ∏è MCP `executing` Event (optional, f√ºr bessere UX)
10. ‚öôÔ∏è Content-Part Events (f√ºr Multi-Content-Responses)
11. ‚öôÔ∏è Refusal/Reasoning Events (f√ºr O1-Modelle)
12. ‚öôÔ∏è Event Audit Log (optional, f√ºr Debugging)

**Hinweis:** Phase 3 kann niedrig priorisiert werden, da MCP-Core-Funktionalit√§t bereits in Phase 1+2 abgedeckt ist.

---

## üß™ Testabdeckung

**Fehlende Tests:**
```java
@Test
void shouldHandleResponseLifecycleEvents() {
    // response.created ‚Üí response.in_progress ‚Üí response.completed
}

@Test
void shouldPersistResponseIdFromCreatedEvent() {
    // Verify conversation.responseId is set
}

@Test
void shouldHandleIncompleteResponses() {
    // response.incomplete mit finish_reason: "length"
}

@Test
void shouldHandleUpstreamErrors() {
    // response.failed, response.error, error
}

@Test
void shouldNotCorruptStreamStateUnderConcurrency() {
    // Parallel text deltas
}

@Test
void shouldHandleClientDisconnectGracefully() {
    // Cancel stream mid-flight
}

@Test
void shouldHandleUnknownToolEvents() {
    // response.web_search_call.in_progress
}
```

---

## üìö Referenzen

- OpenAI Responses API v1: https://v03.api.js.langchain.com/
- Masaic AI Mintlify: https://masaic-ai.mintlify.app/
- Spring Reactor Backpressure: https://projectreactor.io/docs/core/release/reference/#backpressure
- R2DBC Connection Pool: https://r2dbc.io/spec/1.0.0.RELEASE/spec/html/#connections.pooling

---

## ü§ù Kontakt f√ºr R√ºckfragen

Bei Unklarheiten zur Priorisierung oder technischen Details bitte via Pull-Request-Kommentar melden.

---

**Ende des Reports**
